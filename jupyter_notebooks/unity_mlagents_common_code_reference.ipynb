{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dff8044",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# unity mlagents common code to use for RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044c7c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:24:35.531154Z",
     "start_time": "2023-06-14T02:24:26.804016Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import mlagents\n",
    "from mlagents_envs.registry import default_registry\n",
    "from mlagents_envs.environment import ActionTuple, UnityEnvironment as UE\n",
    "\n",
    "env =  UE(file_name=\"stage0_160523\\stage0_copy\",seed=1,side_channels=[])\n",
    "env.reset()\n",
    "#after opening new env, always do env.reset() first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffcec64",
   "metadata": {
    "hidden": true
   },
   "source": [
    "if the env screen that shows up is blank or (not responding), dont fret, you manually right click and open another window or just ignore first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af279509",
   "metadata": {
    "hidden": true
   },
   "source": [
    "if you open a new window when running the code you will have 2 rl_env screens, one that was the error one and the one that is working\n",
    "but then when you run your action loop, the screen that is moving might be one of the other, just alt+tab and check which screen is moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49e31ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:24:38.597919Z",
     "start_time": "2023-06-14T02:24:38.584912Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the environment behavior: stage0?team=0\n"
     ]
    }
   ],
   "source": [
    "behavior_name=list(env.behavior_specs)[0]\n",
    "print(f\"Name of the environment behavior: {behavior_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a47bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:26:10.366660Z",
     "start_time": "2023-06-14T02:26:10.352846Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 1\n",
      "Observation vector shape: [ObservationSpec(shape=(128, 128, 3), dimension_property=(<DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.NONE: 1>), observation_type=<ObservationType.DEFAULT: 0>, name='CameraSensor')]\n"
     ]
    }
   ],
   "source": [
    "behavior_spec=env.behavior_specs[behavior_name]\n",
    "print(f\"Number of observations: {len(behavior_spec.observation_specs)}\")\n",
    "print(f\"Observation vector shape: {behavior_spec.observation_specs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd7d62b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:26:23.380860Z",
     "start_time": "2023-06-14T02:26:23.377604Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action is discrete\n"
     ]
    }
   ],
   "source": [
    "if behavior_spec.action_spec.is_continuous():\n",
    "    print(\"action is continuous\")\n",
    "    \n",
    "if behavior_spec.action_spec.is_discrete():\n",
    "    print(\"action is discrete\")\n",
    "    \n",
    "# our current env uses discrete actions, hence the action spec is discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d86b5f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:26:49.623725Z",
     "start_time": "2023-06-14T02:26:49.615570Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_steps (this means how many agents are requesting for decision, 0 refers to first agent at index 0): [0]\n",
      "terminal steps (this refers to which agents have already reached terminal stage which means already ended): []\n"
     ]
    }
   ],
   "source": [
    "#this line basically gives you a summary of the current state of the env\n",
    "decision_steps,terminal_steps = env.get_steps(behavior_name)\n",
    "#decision steps tell you which agents in the env are still requesting a decision\n",
    "#terminal steps tell you which agents in the env have reached a terminal stage, i.e. ended the episode\n",
    "\n",
    "print(f\"decision_steps (this means how many agents are requesting for decision, 0 refers to first agent at index 0): {list(decision_steps)}\")\n",
    "# if decision steps at the start of the env is [0] means correct cause the env hasnt ended so the agent in the env is still requesting decision\n",
    "\n",
    "print(f\"terminal steps (this refers to which agents have already reached terminal stage which means already ended): {list(terminal_steps)}\")\n",
    "# terminal stage means reached end of the game, e.g. fell of platform, hit the target etc, depending on your env, so if the start of the game, its [] is correct since none of the objects have started moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58eb0b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:27:16.317574Z",
     "start_time": "2023-06-14T02:27:16.298566Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is: Continuous: 0, Discrete: (2, 2, 2, 2)\n",
      "Action size is: 4\n"
     ]
    }
   ],
   "source": [
    "action_space = env.behavior_specs[behavior_name].action_spec\n",
    "\n",
    "print(f\"Action space is: {action_space}\")\n",
    "# actions space is 2,2,2,2 since each of them can do that or do nothing\n",
    "# there are 4 indices since the agent can do 4 actions: move forward, move backward, rotate right, rotate left\n",
    "\n",
    "print(f\"Action size is: {len(action_space[1]) if behavior_spec.action_spec.is_discrete() else len(action_space[0])}\")\n",
    "# action size is 4 since move forward backward rotate right left are 4 different actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6ba889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:28:51.344127Z",
     "start_time": "2023-06-14T02:28:51.329585Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get the agents input (in our case the rgb values, run this command)\n",
    "decision_steps.obs[0].shape #[0] refers to our agent at the 0th index\n",
    "# this corresponds to the rgb input of height width =128, 3 rgb channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6002272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:35:28.994674Z",
     "start_time": "2023-06-14T02:35:28.986778Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 1]]), numpy.ndarray)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to create a random action using unity\n",
    "action = behavior_spec.action_spec.random_action(len(decision_steps))\n",
    "action.discrete,type(action.discrete)\n",
    "#this is an example of random action, there are 4 values, corresponding to 4 possible actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db32f85d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:34:45.323148Z",
     "start_time": "2023-06-14T02:34:45.306588Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlagents_envs.base_env.ActionTuple at 0x24bad8f1080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to pass this action to an agent, you need to first pass the action to a Unity ActionTuple(), this action will be output of model\n",
    "action_tuple=ActionTuple()\n",
    "action_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf68a866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:35:42.202851Z",
     "start_time": "2023-06-14T02:35:42.198850Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_tuple.add_discrete(action.discrete)\n",
    "action_tuple.discrete \n",
    "#action tuple will be of shape (num_agents,num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b8e44",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# now we set the env with the action of the actiontuple generated\n",
    "env.set_actions(behavior_name,action_tuple)\n",
    "\n",
    "#move env by 1 step\n",
    "env.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162d0f2",
   "metadata": {},
   "source": [
    "# sample code to move agent and run episodes using random actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21790581",
   "metadata": {},
   "source": [
    "you need to download the sample zip file as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2b3d84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:42:27.398011Z",
     "start_time": "2023-06-14T02:42:22.297016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment created.\n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# This code is used to close an env that might not have been closed before\n",
    "try:\n",
    "  env.close()\n",
    "except:\n",
    "  pass\n",
    "# -----------------\n",
    "\n",
    "from mlagents_envs.registry import default_registry\n",
    "from mlagents_envs.environment import ActionTuple, UnityEnvironment as UE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "env =  UE(file_name=\"stage0_160523\\stage0_copy\",seed=1,side_channels=[])\n",
    "print(\"environment created.\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "118efa7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T02:56:35.601717Z",
     "start_time": "2023-06-14T02:42:27.399998Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rewards for episode 1/10: -19.0\n",
      "Total rewards for episode 2/10: -38.0\n",
      "Total rewards for episode 3/10: -3.0\n",
      "Total rewards for episode 4/10: 0.0\n",
      "Total rewards for episode 5/10: -53.0\n",
      "Total rewards for episode 6/10: -4.0\n",
      "Total rewards for episode 7/10: -19.0\n",
      "Total rewards for episode 8/10: -1.0\n",
      "Total rewards for episode 9/10: -6.0\n",
      "Total rewards for episode 10/10: -22.0\n"
     ]
    }
   ],
   "source": [
    "behavior_name=list(env.behavior_specs)[0]\n",
    "behavior_spec=env.behavior_specs[behavior_name]\n",
    "\n",
    "num_episodes=10\n",
    "for episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    tracked_agent = -1 # -1 indicates not yet tracking\n",
    "    done = False # For the tracked_agent\n",
    "    episode_rewards = 0 # For the tracked_agent\n",
    "    while not done:\n",
    "        # Track the first agent we see if not tracking\n",
    "        # Note : len(decision_steps) = [number of agents that requested a decision]\n",
    "        if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "            tracked_agent = decision_steps.agent_id[0]\n",
    "            \n",
    "        # Generate an action for all agents\n",
    "        action = behavior_spec.action_spec.random_action(len(decision_steps))\n",
    "        # Set the actions\n",
    "        env.set_actions(behavior_name, action)\n",
    "        # Move the simulation forward\n",
    "        env.step()\n",
    "        \n",
    "        # Get the new simulation results\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "        if tracked_agent in decision_steps: # The agent requested a decision\n",
    "            episode_rewards += decision_steps[tracked_agent].reward\n",
    "        if tracked_agent in terminal_steps: # The agent terminated its episode\n",
    "            episode_rewards += terminal_steps[tracked_agent].reward\n",
    "            done = True #set done = True since agent reach terminal state, episode ends so set to True to break out of loop\n",
    "            \n",
    "    print(f\"Total rewards for episode {episode+1}/{num_episodes}: {episode_rewards}\")\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
